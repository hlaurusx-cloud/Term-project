# app.py
# ê°œì¸ì‹ ìš©í‰ê°€(ìƒí™˜ì˜ˆì¸¡) ë¡œì§€ìŠ¤í‹± + Stepwise(t-test ê¸°ë°˜) + ê³ ê° ì„¸ë¶„í™” Streamlit ì•±

import streamlit as st
import pandas as pd
import numpy as np

import statsmodels.api as sm
from sklearn.model_selection import train_test_split
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score,
    f1_score, confusion_matrix, roc_curve, roc_auc_score
)

import plotly.express as px
import plotly.graph_objects as go

# ------------------------------------------------------------
# ìœ í‹¸ í•¨ìˆ˜: Stepwise Backward Elimination (t-test / p-value ê¸°ë°˜)
# ------------------------------------------------------------
def stepwise_backward_logit(X, y, p_threshold=0.05, max_iter=30):
    """
    statsmodels.Logit + backward elimination
    - p-valueê°€ í° ë³€ìˆ˜ë¥¼ í•˜ë‚˜ì”© ì œê±°
    - X, yëŠ” ë‚´ë¶€ì—ì„œ ìˆ«ìí˜•(float)ìœ¼ë¡œ ë³€í™˜í•˜ê³  NaN ì²˜ë¦¬
    """

    # 1) X, yë¥¼ ìˆ«ìí˜•ìœ¼ë¡œ ê°•ì œ ë³€í™˜
    #    (object, bool, string ë‹¤ ìˆ«ìë¡œ ë°”ê¾¸ê³  ì•ˆ ë˜ë©´ NaN)
    X_num = X.copy()
    X_num = X_num.apply(pd.to_numeric, errors="coerce")
    y_num = pd.to_numeric(y, errors="coerce")

    # 2) yê°€ NaNì¸ í–‰ ì œê±° (ë‘˜ ë‹¤ ê°™ì€ indexë§Œ ì‚¬ìš©)
    mask = ~y_num.isna()
    X_num = X_num.loc[mask]
    y_num = y_num.loc[mask]

    # 3) Xì˜ NaNì€ 0ìœ¼ë¡œ ì±„ìš°ê³ , ë‘˜ ë‹¤ floatë¡œ ìºìŠ¤íŒ…
    X_num = X_num.fillna(0).astype(float)
    y_num = y_num.astype(float)

    # 4) ìƒìˆ˜í•­ ì¶”ê°€ í›„ ì—­ì‹œ floatë¡œ
    X_const = sm.add_constant(X_num, has_constant="add")
    X_const = X_const.astype(float)

    cols = list(X_const.columns)
    removed = []

    # -----------------------------------------
    # Stepwise backward elimination ë°˜ë³µ ì‹œì‘
    # -----------------------------------------
    for _ in range(max_iter):
        # ì—¬ê¸°ì„œ y_num, X_const[cols]ëŠ” ì „ë¶€ floatì´ì–´ì•¼ í•¨
        model = sm.Logit(y_num, X_const[cols]).fit(disp=False)
        pvalues = model.pvalues

        # const ì œì™¸í•œ ê°€ì¥ í° p-value ì°¾ê¸°
        pvalues_no_const = pvalues.drop("const", errors="ignore")
        worst_feature = pvalues_no_const.idxmax()
        worst_p = pvalues_no_const.max()

        # ì œê±° ì¡°ê±´ ì²´í¬
        if worst_p > p_threshold and len(cols) > 2:
            cols.remove(worst_feature)
            removed.append((worst_feature, worst_p))
        else:
            break

    # -----------------------------------------
    # ëª¨ë“  ì œê±° ì‘ì—… ë â†’ ìµœì¢… ëª¨ë¸ ì í•©
    # -----------------------------------------
    final_model = sm.Logit(y_num, X_const[cols]).fit(disp=False)

    return final_model, cols, removed



# ------------------------------------------------------------
# Streamlit UI
# ------------------------------------------------------------
st.set_page_config(
    page_title="ê°œì¸ì‹ ìš©í‰ê°€(Logit) â€“ ìƒí™˜ì˜ˆì¸¡",
    layout="wide"
)

st.title("ğŸ“Š ê°œì¸ì‹ ìš©í‰ê°€ â€“ Logit (ìƒí™˜ì˜ˆì¸¡) + ê³ ê°ì„¸ë¶„í™”")

# ------------------------------------------------------------
# 1. ë°ì´í„° ì—…ë¡œë“œ
# ------------------------------------------------------------
st.sidebar.header("1. ë°ì´í„° ì—…ë¡œë“œ")
uploaded = st.sidebar.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

if uploaded is None:
    st.info("ğŸ‘ˆ ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ë¨¼ì € ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()

df = pd.read_csv(uploaded)
st.write("### ğŸ“ ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
st.dataframe(df.head())

# ------------------------------------------------------------
# 2. íƒ€ê¹ƒ ë³€ìˆ˜/ì„¤ì • ì„ íƒ
# ------------------------------------------------------------
st.sidebar.header("2. ë³€ìˆ˜ ì„¤ì •")

all_cols = df.columns.tolist()

target_col = st.sidebar.selectbox(
    "íƒ€ê¹ƒ ë³€ìˆ˜ (ë¶€ì‹¤ ì—¬ë¶€ / ìƒí™˜ ìƒíƒœ)",
    options=all_cols,
    index=all_cols.index("loan_status") if "loan_status" in all_cols else 0
)

# íƒ€ê¹ƒì´ ë¬¸ìí˜•ì´ë©´, ì–´ëŠ ê°’(ë¼ë²¨)ì„ 'ë¶€ì‹¤(1)'ë¡œ ë³¼ì§€ ì„ íƒ
if df[target_col].dtype == "object":
    st.sidebar.markdown("**íƒ€ê¹ƒì´ ë²”ì£¼í˜•ì…ë‹ˆë‹¤. ë¶€ì‹¤(=1)ë¡œ ë³¼ ê°’ì„ ì„ íƒí•˜ì„¸ìš”.**")
    unique_vals = df[target_col].dropna().unique().tolist()
    positive_label = st.sidebar.selectbox(
        "ë¶€ì‹¤(1)ë¡œ ê°„ì£¼í•  ê°’(ë¼ë²¨)",
        options=unique_vals
    )
    y_raw = df[target_col].apply(lambda x: 1 if x == positive_label else 0)
else:
    # ì´ë¯¸ 0/1 ì´ë¼ê³  ê°€ì •
    y_raw = df[target_col]
    positive_label = 1

st.sidebar.write("---")

test_size = st.sidebar.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨", 0.1, 0.5, 0.3, 0.05)
p_threshold = st.sidebar.slider("Stepwise ì œê±° ê¸°ì¤€ p-value", 0.01, 0.2, 0.05, 0.01)
random_state = st.sidebar.number_input("Random State", 0, 9999, 42)

st.sidebar.write("---")
st.sidebar.header("3. ê³ ê° ì„¸ë¶„í™” ì„¤ì •")

segmentation_method = st.sidebar.radio(
    "ì„¸ë¶„í™” ë°©ì‹ ì„ íƒ",
    ["ìˆ˜ë™ ì„ê³„ê°’(Threshold)", "ë¶„ìœ„ìˆ˜(Quantile) ê¸°ë°˜"],
)

if segmentation_method == "ìˆ˜ë™ ì„ê³„ê°’(Threshold)":
    st.sidebar.markdown("ì˜ˆ: 0.05, 0.15, 0.30, 0.50 ë“±")
    th1 = st.sidebar.number_input("ë“±ê¸‰ A/B ê²½ê³„ (ì˜ˆ: 0.05)", 0.0, 1.0, 0.05, 0.01)
    th2 = st.sidebar.number_input("ë“±ê¸‰ B/C ê²½ê³„ (ì˜ˆ: 0.15)", 0.0, 1.0, 0.15, 0.01)
    th3 = st.sidebar.number_input("ë“±ê¸‰ C/D ê²½ê³„ (ì˜ˆ: 0.30)", 0.0, 1.0, 0.30, 0.01)
    th4 = st.sidebar.number_input("ë“±ê¸‰ D/E ê²½ê³„ (ì˜ˆ: 0.50)", 0.0, 1.0, 0.50, 0.01)
else:
    st.sidebar.markdown("ë¶„ìœ„ìˆ˜ ê¸°ë°˜ 5ê°œ ê·¸ë£¹ (A~E)ìœ¼ë¡œ ìë™ ë¶„í• í•©ë‹ˆë‹¤.")

# ------------------------------------------------------------
# 3. ì „ì²˜ë¦¬: X, y êµ¬ì„± ë° ë”ë¯¸ë³€ìˆ˜ ìƒì„±
# ------------------------------------------------------------
st.header("1ï¸âƒ£ ì „ì²˜ë¦¬ ë° ë³€ìˆ˜ êµ¬ì„±")

# íƒ€ê¹ƒ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ì»¬ëŸ¼ì„ ì„¤ëª…ë³€ìˆ˜ í›„ë³´ë¡œ ì‚¬ìš©
feature_cols = [c for c in all_cols if c != target_col]
X_raw = df[feature_cols].copy()
y = y_raw.copy()

st.markdown("#### ğŸ” ê²°ì¸¡ì¹˜ ì²˜ë¦¬")
st.write("ê¸°ë³¸ì ìœ¼ë¡œ **ê²°ì¸¡ì¹˜ í–‰ì€ ì œê±°(dropna)** í•©ë‹ˆë‹¤.")
data = pd.concat([X_raw, y], axis=1).dropna()
X_raw = data[feature_cols]
y = data[target_col] if target_col in data.columns else y.loc[data.index]

st.markdown("#### ğŸ”¢ ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”© (One-Hot)")
cat_cols = X_raw.select_dtypes(include=["object", "category"]).columns.tolist()
num_cols = X_raw.select_dtypes(exclude=["object", "category"]).columns.tolist()

st.write(f"- ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ê°œìˆ˜: {len(num_cols)}")
st.write(f"- ë²”ì£¼í˜• ë³€ìˆ˜ ê°œìˆ˜: {len(cat_cols)}")

X_encoded = pd.get_dummies(X_raw, columns=cat_cols, drop_first=True)

st.write("ì¸ì½”ë”© í›„ Xì˜ shape:", X_encoded.shape)
st.dataframe(X_encoded.head())

# ------------------------------------------------------------
# 4. Train/Test Split (+ stratify ì—ëŸ¬ ëŒ€ë¹„)
# ------------------------------------------------------------
st.header("2ï¸âƒ£ í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• ")

# íƒ€ê¹ƒ ë¶„í¬ í™•ì¸
st.markdown("#### ğŸ” íƒ€ê¹ƒ(ë¶€ì‹¤ ì—¬ë¶€) ë¶„í¬")
class_counts = y.value_counts()
st.write(class_counts)

# ê¸°ë³¸ì€ stratify=y ë¡œ ì‹œë„í•˜ë˜, ì—ëŸ¬ ë‚˜ë©´ stratify=None ìœ¼ë¡œ fallback
try:
    X_train, X_test, y_train, y_test = train_test_split(
        X_encoded,
        y,
        test_size=test_size,
        random_state=random_state,
        stratify=y   # ìš°ì„  ê³„ì¸µ ìƒ˜í”Œë§ ì‹œë„
    )
except ValueError as e:
    st.warning(
        "âš ï¸ stratify=y ì˜µì…˜ìœ¼ë¡œ Train/Testë¥¼ ë‚˜ëˆ„ëŠ” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. "
        "íƒ€ê¹ƒ í´ë˜ìŠ¤ ì¤‘ ì¼ë¶€ê°€ ë„ˆë¬´ ì ì„ ìˆ˜ ìˆì–´ìš”.\n"
        "â†’ stratify ì—†ì´(ë¬´ì‘ìœ„ ë¶„í• ) ë‹¤ì‹œ ì‹œë„í•©ë‹ˆë‹¤.\n\n"
        f"ì›ë³¸ ì˜¤ë¥˜ ë©”ì‹œì§€(ì°¸ê³ ìš©): {e}"
    )
    X_train, X_test, y_train, y_test = train_test_split(
        X_encoded,
        y,
        test_size=test_size,
        random_state=random_state,
        stratify=None
    )

st.write(f"- Train size: {X_train.shape[0]}  |  Test size: {X_test.shape[0]}")
st.write(f"- ë³€ìˆ˜ ê°œìˆ˜: {X_train.shape[1]}")


# ------------------------------------------------------------
# 5. Stepwise + Logit ëª¨ë¸ í•™ìŠµ
# ------------------------------------------------------------
st.header("3ï¸âƒ£ ë¡œì§€ìŠ¤í‹± íšŒê·€(Logit) + Stepwise(t-test ê¸°ë°˜)")

with st.spinner("Stepwise backward eliminationìœ¼ë¡œ ë³€ìˆ˜ ì„ íƒ ì¤‘..."):
    model_final, selected_cols, removed_list = stepwise_backward_logit(
        X_train, y_train, p_threshold=p_threshold
    )

st.subheader("ğŸ“Œ ìµœì¢… ì„ íƒëœ ë³€ìˆ˜ ëª©ë¡")
st.write(selected_cols)

if removed_list:
    st.subheader("âŒ ì œê±°ëœ ë³€ìˆ˜ (ë³€ìˆ˜ëª…, p-value)")
    removed_df = pd.DataFrame(removed_list, columns=["feature", "p_value"])
    st.dataframe(removed_df)
else:
    st.write("Stepwise ê³¼ì •ì—ì„œ ì œê±°ëœ ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

st.subheader("ğŸ“„ ìµœì¢… Logit ëª¨ë¸ ìš”ì•½ (statsmodels)")
st.text(model_final.summary().as_text())

# ------------------------------------------------------------
# 6. ì˜ˆì¸¡ ë° ì„±ëŠ¥í‰ê°€
# ------------------------------------------------------------
st.header("4ï¸âƒ£ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")

# train/test ë°ì´í„°ì— ê°™ì€ ì„ íƒ ë³€ìˆ˜ë§Œ ì‚¬ìš©
X_train_sel = sm.add_constant(X_train[selected_cols[1:]], has_constant="add")
X_test_sel = sm.add_constant(X_test[selected_cols[1:]], has_constant="add")

# ì˜ˆì¸¡í™•ë¥  (ê¸°ë³¸: ë¶€ì‹¤(=1)ì˜ í™•ë¥ )
train_pred_prob = model_final.predict(X_train_sel)
test_pred_prob = model_final.predict(X_test_sel)

# 0.5 ê¸°ì¤€ìœ¼ë¡œ ì´í•­ ë¶„ë¥˜
test_pred_label = (test_pred_prob >= 0.5).astype(int)

acc = accuracy_score(y_test, test_pred_label)
prec = precision_score(y_test, test_pred_label, zero_division=0)
rec = recall_score(y_test, test_pred_label, zero_division=0)
f1 = f1_score(y_test, test_pred_label, zero_division=0)
fpr, tpr, _ = roc_curve(y_test, test_pred_prob)
auc = roc_auc_score(y_test, test_pred_prob)

col1, col2, col3, col4, col5 = st.columns(5)
col1.metric("Accuracy", f"{acc:.3f}")
col2.metric("Precision", f"{prec:.3f}")
col3.metric("Recall", f"{rec:.3f}")
col4.metric("F1-score", f"{f1:.3f}")
col5.metric("ROC AUC", f"{auc:.3f}")

# Confusion Matrix
cm = confusion_matrix(y_test, test_pred_label)
st.subheader("ğŸ”¢ í˜¼ë™í–‰ë ¬ (Confusion Matrix)")
cm_df = pd.DataFrame(
    cm,
    index=[f"ì‹¤ì œ 0(ì •ìƒ)", f"ì‹¤ì œ 1(ë¶€ì‹¤)"],
    columns=[f"ì˜ˆì¸¡ 0(ì •ìƒ)", f"ì˜ˆì¸¡ 1(ë¶€ì‹¤)"]
)
st.dataframe(cm_df)

# ROC Curve
st.subheader("ğŸ“ˆ ROC Curve")
fig_roc = go.Figure()
fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode="lines", name=f"ROC curve (AUC={auc:.3f})"))
fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode="lines", name="Random", line=dict(dash="dash")))
fig_roc.update_layout(
    xaxis_title="False Positive Rate",
    yaxis_title="True Positive Rate",
    width=700,
    height=500
)
st.plotly_chart(fig_roc, use_container_width=True)

# Test set ì˜ˆì¸¡í™•ë¥  ë¶„í¬
st.subheader("ğŸ“Š Test ë°ì´í„° ì˜ˆì¸¡í™•ë¥  ë¶„í¬(ë¶€ì‹¤ í™•ë¥ )")
hist_df = pd.DataFrame({
    "pred_prob": test_pred_prob,
    "actual": y_test.values
})
fig_hist = px.histogram(
    hist_df,
    x="pred_prob",
    color="actual",
    nbins=30,
    barmode="overlay",
    labels={"actual": "ì‹¤ì œ ë¶€ì‹¤ ì—¬ë¶€", "pred_prob": "ë¶€ì‹¤ ì˜ˆì¸¡ í™•ë¥ "}
)
fig_hist.update_traces(opacity=0.6)
st.plotly_chart(fig_hist, use_container_width=True)

# ------------------------------------------------------------
# 7. ì „ì²´ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ + ê³ ê° ì„¸ë¶„í™”
# ------------------------------------------------------------
st.header("5ï¸âƒ£ ì˜ˆì¸¡í™•ë¥  ê¸°ë°˜ ê³ ê° ì„¸ë¶„í™” ë° ë¶€ì‹¤ìœ¨")

# ì „ì²´ ë°ì´í„°(ê²°ì¸¡ ì œê±° í›„)ì— ëŒ€í•´ ì˜ˆì¸¡ ìˆ˜í–‰
X_all_encoded = X_encoded.loc[X_train.index.union(X_test.index)]  # ì´ë¯¸ dropna ë˜ì—ˆìŒ
y_all = y.loc[X_all_encoded.index]

X_all_sel = X_all_encoded[selected_cols[1:]].copy()
X_all_sel = X_all_sel.apply(pd.to_numeric, errors="coerce").fillna(0)
X_all_sel = sm.add_constant(X_all_sel, has_constant="add")

all_pred_prob = model_final.predict(X_all_sel)

seg_df = pd.DataFrame({
    "pred_prob": all_pred_prob,
    "actual": y_all.values
})

# ì„¸ë¶„í™”
if segmentation_method == "ìˆ˜ë™ ì„ê³„ê°’(Threshold)":
    def assign_segment(p):
        if p < th1:
            return "A (ë§¤ìš° ìš°ëŸ‰)"
        elif p < th2:
            return "B (ìš°ëŸ‰)"
        elif p < th3:
            return "C (ì£¼ì˜)"
        elif p < th4:
            return "D (ê³ ìœ„í—˜)"
        else:
            return "E (ë§¤ìš° ê³ ìœ„í—˜)"
    seg_df["segment"] = seg_df["pred_prob"].apply(assign_segment)
else:
    # ë¶„ìœ„ìˆ˜ ê¸°ë°˜ 5ê°œ ê·¸ë£¹ (pred_prob ë‚®ì„ìˆ˜ë¡ A, ë†’ì„ìˆ˜ë¡ E)
    seg_df["segment"] = pd.qcut(
        seg_df["pred_prob"],
        5,
        labels=["A (ë§¤ìš° ìš°ëŸ‰)", "B (ìš°ëŸ‰)", "C (ì£¼ì˜)", "D (ê³ ìœ„í—˜)", "E (ë§¤ìš° ê³ ìœ„í—˜)"]
    )

# ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶€ì‹¤ìœ¨ ê³„ì‚°
group_stats = seg_df.groupby("segment").agg(
    ê³ ê°ìˆ˜=("actual", "count"),
    ë¶€ì‹¤ìˆ˜=("actual", "sum"),
    ë¶€ì‹¤ìœ¨=("actual", "mean"),
    í‰ê· ë¶€ì‹¤í™•ë¥ =("pred_prob", "mean")
).reset_index()

group_stats["ë¶€ì‹¤ìœ¨(%)"] = group_stats["ë¶€ì‹¤ìœ¨"] * 100
group_stats["í‰ê· ë¶€ì‹¤í™•ë¥ (%)"] = group_stats["í‰ê· ë¶€ì‹¤í™•ë¥ "] * 100

st.subheader("ğŸ“‹ ì„¸ê·¸ë¨¼íŠ¸ë³„ ê³ ê°ìˆ˜, ë¶€ì‹¤ìœ¨, í‰ê·  ì˜ˆì¸¡í™•ë¥ ")
st.dataframe(group_stats[["segment", "ê³ ê°ìˆ˜", "ë¶€ì‹¤ìˆ˜", "ë¶€ì‹¤ìœ¨(%)", "í‰ê· ë¶€ì‹¤í™•ë¥ (%)"]])

# ë¶€ì‹¤ìœ¨ ë°” ì°¨íŠ¸
st.subheader("ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸ë³„ ë¶€ì‹¤ìœ¨ ì‹œê°í™”")
fig_seg = px.bar(
    group_stats,
    x="segment",
    y="ë¶€ì‹¤ìœ¨(%)",
    text="ë¶€ì‹¤ìœ¨(%)",
    labels={"segment": "ì„¸ê·¸ë¨¼íŠ¸", "ë¶€ì‹¤ìœ¨(%)": "ë¶€ì‹¤ìœ¨(%)"},
)
fig_seg.update_traces(texttemplate="%{text:.1f}", textposition="outside")
fig_seg.update_layout(yaxis=dict(range=[0, group_stats["ë¶€ì‹¤ìœ¨(%)"].max() * 1.2]))
st.plotly_chart(fig_seg, use_container_width=True)

# ì„¸ê·¸ë¨¼íŠ¸ ë¹„ì¤‘ íŒŒì´ì°¨íŠ¸
st.subheader("ğŸ§© ì„¸ê·¸ë¨¼íŠ¸ë³„ ê³ ê° ë¹„ì¤‘")
fig_pie = px.pie(
    group_stats,
    names="segment",
    values="ê³ ê°ìˆ˜",
    hole=0.3
)
st.plotly_chart(fig_pie, use_container_width=True)

# ------------------------------------------------------------
# 8. ì „ëµ ì œì•ˆ í…ìŠ¤íŠ¸
# ------------------------------------------------------------
st.header("6ï¸âƒ£ ê³ ê° ì„¸ë¶„í™” ê¸°ë°˜ ì „ëµ ì œì•ˆ (ìš”ì•½ í…ìŠ¤íŠ¸)")

st.markdown("""
- **A (ë§¤ìš° ìš°ëŸ‰)**: ë¶€ì‹¤ í™•ë¥ ì´ ë§¤ìš° ë‚®ì€ ê·¸ë£¹ â†’ **ìš°ëŒ€ê¸ˆë¦¬, í•œë„ í™•ëŒ€, ë¦¬ì›Œë“œ ì œê³µ** ê°€ëŠ¥  
- **B (ìš°ëŸ‰)**: ì•ˆì •ì ì¸ ê·¸ë£¹ â†’ **í‘œì¤€ ê¸ˆë¦¬ ìœ ì§€**, ì¥ê¸° ê³ ê°ìœ¼ë¡œ ìœ¡ì„±  
- **C (ì£¼ì˜)**: í‰ê·  ìˆ˜ì¤€ ì´ìƒì˜ ë¦¬ìŠ¤í¬ â†’ **ëª¨ë‹ˆí„°ë§ ê°•í™”**, ì†Œì•¡/ë‹¨ê¸° ìœ„ì£¼ ìŠ¹ì¸  
- **D (ê³ ìœ„í—˜)**: ë†’ì€ ë¦¬ìŠ¤í¬ â†’ **ê¸ˆë¦¬ ì¸ìƒ, ë³´ì¦/ë‹´ë³´ ìš”êµ¬**, ìŠ¹ì¸ ê¸°ì¤€ ê°•í™”  
- **E (ë§¤ìš° ê³ ìœ„í—˜)**: ë§¤ìš° ë†’ì€ ë¦¬ìŠ¤í¬ â†’ **ëŒ€ì¶œ ê±°ì ˆ ë˜ëŠ” ë§¤ìš° ì œí•œì ì¸ ìŠ¹ì¸** ê¶Œì¥  
""")
