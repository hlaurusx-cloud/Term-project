import io
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
import statsmodels.api as sm
from scipy import stats
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (
    roc_auc_score, roc_curve,
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix
)

# ----------------------------
# Streamlit ê¸°ë³¸ ì„¤ì •
# ----------------------------
st.set_page_config(page_title="ì‹ ê²½ë§ ê¸°ë°˜ ê°œì¸ì‹ ìš©í‰ê°€(ë¶€ì‹¤ì˜ˆì¸¡)", layout="wide")
st.title("ì‹ ê²½ë§(MLP) ê¸°ë°˜ ê°œì¸ì‹ ìš©í‰ê°€ ëª¨ë¸")

# ----------------------------
# ìœ í‹¸ í•¨ìˆ˜
# ----------------------------
def safe_read_csv(uploaded_file) -> pd.DataFrame:
    raw = uploaded_file.read()
    for enc in ["utf-8", "cp949", "euc-kr"]:
        try:
            return pd.read_csv(io.BytesIO(raw), encoding=enc)
        except Exception:
            continue
    return pd.read_csv(io.BytesIO(raw), encoding_errors="ignore")

def metrics_from_proba(y_true, proba, threshold=0.5):
    pred = (proba >= threshold).astype(int)
    return {
        "AUC": roc_auc_score(y_true, proba),
        "Accuracy": accuracy_score(y_true, pred),
        "Precision": precision_score(y_true, pred, zero_division=0),
        "Recall": recall_score(y_true, pred, zero_division=0),
        "F1": f1_score(y_true, pred, zero_division=0),
        "CM": confusion_matrix(y_true, pred),
        "pred": pred
    }

def plot_roc(y_true, proba, title="ROC Curve"):
    fpr, tpr, _ = roc_curve(y_true, proba)
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.plot(fpr, tpr)
    ax.plot([0, 1], [0, 1], linestyle="--")
    ax.set_xlabel("False Positive Rate")
    ax.set_ylabel("True Positive Rate")
    ax.set_title(title)
    return fig

def make_quantile_grades(proba, n_bins=5):
    # ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ìœ„í—˜ë“±ê¸‰ ìƒì„±(ë‚®ìŒ=A, ë†’ìŒ=...)
    s = pd.Series(proba)
    # ì¤‘ë³µê°’ì´ ë§ì„ ë•Œ qcut ì‹¤íŒ¨ ë°©ì§€: rank ì‚¬ìš©
    r = s.rank(method="average")
    q = pd.qcut(r, q=n_bins, labels=False, duplicates="drop")
    actual_bins = int(pd.Series(q).nunique())
    labels = [chr(ord("A") + i) for i in range(actual_bins)]  # A,B,C...
    grade = pd.Series(q).map(lambda i: labels[int(i)] if pd.notna(i) else labels[-1])
    return grade, labels

def segmentation_table(y_true, proba, n_bins=10):
    import numpy as np
    import pandas as pd

    # 1ï¸âƒ£ å¼ºåˆ¶ 1D
    y_true = np.asarray(y_true).ravel()
    proba  = np.asarray(proba).ravel()

    # 2ï¸âƒ£ é•¿åº¦æ£€æŸ¥ï¼ˆå…³é”®ï¼‰
    if len(y_true) != len(proba):
        raise ValueError(
            f"[segmentation_table] é•¿åº¦ä¸ä¸€è‡´: y_true={len(y_true)}, proba={len(proba)}"
        )

    # 3ï¸âƒ£ åˆ†ç®±ï¼ˆæŒ‰æ¦‚ç‡åˆ†ä½æ•°ï¼‰
    grade = pd.qcut(proba, q=n_bins, labels=False, duplicates="drop") + 1

    temp = pd.DataFrame({
        "PD": proba,
        "Y": y_true,
        "Grade": grade
    })

    agg = (
        temp.groupby("Grade")
        .agg(
            cnt=("Y", "size"),
            bad=("Y", "sum"),
            avg_pd=("PD", "mean")
        )
        .reset_index()
    )

    agg["bad_rate"] = agg["bad"] / agg["cnt"]

    return agg, temp


def plot_default_rate_by_grade(agg_df, title="Default Rate by Risk Grade"):
    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.bar(agg_df["Grade"], agg_df["Default_Rate"])
    ax.set_xlabel("Risk Grade (A=Low â†’ High)")
    ax.set_ylabel("Observed Default Rate")
    ax.set_title(title)
    return fig


# ----------------------------
# ì„¸ì…˜ ìƒíƒœ
# ----------------------------
if "df" not in st.session_state:
    st.session_state.df = None
if "prep_pipe" not in st.session_state:
    st.session_state.prep_pipe = None
if "model" not in st.session_state:
    st.session_state.model = None
if "X_test" not in st.session_state:
    st.session_state["X_test"] = None
if "y_test" not in st.session_state:
    st.session_state.y_test = None
if "proba_test" not in st.session_state:
    st.session_state.proba_test = None
if "feature_cols" not in st.session_state:
    st.session_state.feature_cols = None
if "target_col" not in st.session_state:
    st.session_state.target_col = None


# ----------------------------
# ë°ì´í„°ë§ˆì´ë‹ ì ˆì°¨ íƒ­ êµ¬ì„±
# ----------------------------
tabs = st.tabs([
    "1) ë°ì´í„° íƒìƒ‰(EDA)",
    "2) ë°ì´í„° ì „ì²˜ë¦¬",
    "3) ëª¨ë¸ë§(ì‹ ê²½ë§)",
    "4) ì„±ëŠ¥í‰ê°€",
    "5) PD ê¸°ë°˜ ê³ ê°ì„¸ë¶„í™”/ë¶€ì‹¤ìœ¨"
])

# ============================================================
# 0) ë°ì´í„° ì—…ë¡œë“œ (ê³µí†µ)
# ============================================================
st.sidebar.header("ë°ì´í„° ì—…ë¡œë“œ")
uploaded = st.sidebar.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])

if uploaded is not None:
    df = safe_read_csv(uploaded)
    st.session_state.df = df

df = st.session_state.df
if df is None:
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()
# ============================================================
# 1) ë°ì´í„° ì´í•´(EDA)
# ============================================================
with tabs[0]:
    st.subheader("1) ë°ì´í„° íƒìƒ‰(EDA): ë³€ìˆ˜ í™•ì¸, ê¸°ì´ˆí†µê³„, íƒ€ê¹ƒ ë¶„í¬")

    st.write("ë°ì´í„° í¬ê¸°:", df.shape)
    st.write("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
    st.dataframe(df.head(5), use_container_width=True)
    
    st.write("ê¸°ì´ˆ í†µê³„(ìˆ˜ì¹˜í˜•)")
    st.dataframe(df.describe(include=[np.number]).T, use_container_width=True)

    # íƒ€ê¹ƒ ë³€ìˆ˜: not.fully.paid ê³ ì • + ë””ìì¸ ìœ ì§€(ì„ íƒ UIëŠ” ìœ ì§€í•˜ë˜ ë¹„í™œì„±í™”)
    if "not.fully.paid" not in df.columns:
        st.error("íƒ€ê¹ƒ ë³€ìˆ˜ 'not.fully.paid' ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    default_target = "not.fully.paid"
    target_col = st.selectbox(
        "íƒ€ê¹ƒ(Y) ì»¬ëŸ¼ ì„ íƒ",
        options=df.columns.tolist(),
        index=df.columns.tolist().index(default_target),
        disabled=True  # âœ… ì„ íƒ ê¸°ëŠ¥ë§Œ ì œê±°
    )
    st.session_state.target_col = target_col

    # íƒ€ê¹ƒ ë¶„í¬
    y_raw = df[target_col]
    st.write("íƒ€ê¹ƒ ë¶„í¬")
    st.dataframe(
        y_raw.value_counts(dropna=False).rename_axis("value").to_frame("count"),
        use_container_width=True
    )

    
    # ------------------------------------------------------------
    # EDA ì‹œê°í™” (êµì²´ ë²„ì „)
    # ------------------------------------------------------------
    st.markdown("## ğŸ“Š EDA ì‹œê°í™”")

    # 1ï¸âƒ£ íƒ€ê¹ƒ ë³€ìˆ˜ ë¶„í¬ (Count + ë¶ˆê· í˜• í™•ì¸)
    st.markdown("### 1ï¸âƒ£ íƒ€ê¹ƒ ë³€ìˆ˜ ë¶„í¬")
    target_cnt = y_raw.value_counts().sort_index()
    target_ratio = (target_cnt / target_cnt.sum() * 100).round(2)

    fig, ax = plt.subplots()
    ax.bar(target_cnt.index.astype(str), target_cnt.values)
    ax.set_xlabel("Target (0 = ì •ìƒ, 1 = ë¶€ì‹¤)")
    ax.set_ylabel("Count")
    ax.set_title("Target Distribution")
    st.pyplot(fig)

    st.dataframe(
        pd.DataFrame({"count": target_cnt, "ratio(%)": target_ratio}),
        use_container_width=True
    )

    st.caption(
        "í•´ì„: 1(ë¶€ì‹¤)ë³´ë‹¤ 0(ì •ìƒ)ì˜ ë¹„ìœ¨ì´ ë§¤ìš° í° ê²½ìš°, "
        "ë¡œì§€ìŠ¤í‹±/ì‹ ê²½ë§ ë“± ë¶„ë¥˜ ëª¨ë¸ì—ì„œ ì˜ˆì¸¡ í¸í–¥ ë° ì„±ëŠ¥ì§€í‘œ í•´ì„ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )

    # 2ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì„ íƒ â†’ íƒ€ê¹ƒë³„ ë¶„í¬ ë¹„êµ(Boxplot)
    st.markdown("### 2ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì˜ íƒ€ê¹ƒë³„ ë¶„í¬ ë¹„êµ")
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    num_cols = [c for c in num_cols if c != target_col]

    if len(num_cols) == 0:
        st.warning("ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        selected_var = st.selectbox("ë¶„í¬ë¥¼ ë¹„êµí•  ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ì„ íƒ", options=num_cols, key="eda_selected_num")

        tmp = df[[selected_var, target_col]].dropna()
        if tmp[target_col].nunique() == 2:
            g0 = tmp[tmp[target_col] == 0][selected_var]
            g1 = tmp[tmp[target_col] == 1][selected_var]

            fig, ax = plt.subplots()
            ax.boxplot([g0, g1], labels=["Target = 0", "Target = 1"])
            ax.set_title(f"{selected_var} : Targetë³„ ë¶„í¬ ë¹„êµ")
            ax.set_ylabel(selected_var)
            st.pyplot(fig)

            st.caption(
                "í•´ì„: ë‘ ê·¸ë£¹ì˜ ì¤‘ì•™ê°’Â·ë¶„ì‚° ì°¨ì´ê°€ í´ìˆ˜ë¡ í•´ë‹¹ ë³€ìˆ˜ëŠ” ë¶€ì‹¤ ì—¬ë¶€ë¥¼ êµ¬ë¶„í•˜ëŠ” ë° ìœ ì˜ë¯¸í•  ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
            )

            # 3ï¸âƒ£ ë¶„í¬ ì§„ë‹¨ (ì™œë„Â·ì²¨ë„ + ì •ê·œì„± ì°¸ê³ )
            st.markdown("### 3ï¸âƒ£ ë¶„í¬ ì§„ë‹¨ (ì°¸ê³ )")
            x = tmp[selected_var]
            st.write(f"- ì™œë„ (Skewness): {stats.skew(x):.4f}")
            st.write(f"- ì²¨ë„ (Kurtosis, fisher): {stats.kurtosis(x, fisher=True):.4f}")

            if len(x) >= 3:
                x_sample = x.sample(n=min(5000, len(x)), random_state=42)
                _, p_value = stats.shapiro(x_sample)
                st.write(f"- Shapiro-Wilk p-value (í‘œë³¸â‰¤5000): {p_value:.6f}")

            st.caption(
                "ì°¸ê³ : ì •ê·œì„±ì€ ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ í•„ìˆ˜ ì „ì œëŠ” ì•„ë‹ˆì§€ë§Œ, ê·¹ë‹¨ì  ì™œë„/ì´ìƒì¹˜ëŠ” ê³„ìˆ˜ ì¶”ì •ê³¼ ëª¨ë¸ ì•ˆì •ì„±ì— ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        else:
            st.info("íƒ€ê¹ƒì´ ì´ì§„(0/1) í˜•íƒœê°€ ì•„ë‹ˆì–´ì„œ íƒ€ê¹ƒë³„ ë°•ìŠ¤í”Œë¡¯ ë¹„êµë¥¼ ìƒëµí•©ë‹ˆë‹¤.")

    # 4ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìƒê´€ê´€ê³„ (ë‹¤ì¤‘ê³µì„ ì„± í™•ì¸)
    st.markdown("### 4ï¸âƒ£ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ ìƒê´€ê´€ê³„(Heatmap)")
    num_df = df.select_dtypes(include=[np.number]).copy()
    if num_df.shape[1] >= 2:
        corr = num_df.corr(numeric_only=True)

        fig, ax = plt.subplots(figsize=(10, 6))
        im = ax.imshow(corr.values)
        ax.set_xticks(range(len(corr.columns)))
        ax.set_yticks(range(len(corr.columns)))
        ax.set_xticklabels(corr.columns, rotation=90)
        ax.set_yticklabels(corr.columns)
        ax.set_title("Correlation Heatmap (Numeric Variables)")
        fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        st.pyplot(fig)

        st.caption("í•´ì„: ìƒê´€ê³„ìˆ˜ê°€ ë§¤ìš° ë†’ì€ ë³€ìˆ˜ ìŒì€ ë‹¤ì¤‘ê³µì„ ì„± ë¬¸ì œë¥¼ ìœ ë°œí•  ìˆ˜ ìˆì–´, ë³€ìˆ˜ ì„ íƒ/ì¶•ì†Œê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.info("ìƒê´€ê´€ê³„ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


# ============================================================
# 2) ë°ì´í„° ì „ì²˜ë¦¬ (Wizard-like / ë‹¨ê³„ ê³ ì •í˜•)
# â‘  T-test (p<=0.05) -> í†µê³¼ featureë§Œ í‘œì‹œ (ìˆ˜ì¹˜í˜•ë§Œ)
# â‘¡ ì „ì²˜ë¦¬ ë²„íŠ¼ -> ì´ìƒì¹˜(IQR,k=1.5)/ê²°ì¸¡ì¹˜ ì œê±° + ì›í•« (ìŠ¤ì¼€ì¼ë§ì€ â‘¢ì—ì„œ)
# â‘¢ ë°ì´í„° ë¶„í• (8:2) + Train ê¸°ì¤€ í‘œì¤€í™”
#    + "ë¶„ëª¨ë¸ ì €ì¥": Logit(ìˆ˜ì¹˜í˜•ë§Œ) / MLP(ì›í•« í¬í•¨ ì „ì²´)
# ============================================================
with tabs[1]:
    st.subheader("2) ë°ì´í„° ì „ì²˜ë¦¬")

    # -----------------------------
    # ìƒíƒœ ì´ˆê¸°í™” (Reset ë²„íŠ¼ ì—†ìŒ)
    # -----------------------------
    if "done_1" not in st.session_state: st.session_state["done_1"] = False
    if "done_2" not in st.session_state: st.session_state["done_2"] = False
    if "done_3" not in st.session_state: st.session_state["done_3"] = False

    # -----------------------------
    # ë°ì´í„°/íƒ€ê¹ƒ í™•ì¸ (ê³¼ì œ ì¡°ê±´: not.fully.paid ê³ ì •)
    # -----------------------------
    if df is None:
        st.warning("ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”.")
        st.stop()

    target_col = "not.fully.paid"
    st.session_state["target_col"] = target_col

    if target_col not in df.columns:
        st.error("íƒ€ê¹ƒ ë³€ìˆ˜ 'not.fully.paid' ì»¬ëŸ¼ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        st.stop()

    st.info(f"íƒ€ê¹ƒ(Y): {target_col}")

    # =========================================================
    # â‘  T-test (p<=0.05 ê³ ì •)
    # =========================================================
    st.markdown("## â‘  T-test ê¸°ë°˜ Feature 1ì°¨ ì„ ë³„")
    st.caption("ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë§Œ, not.fully.paid(0/1) ê¸°ì¤€, p-value â‰¤ 0.05 í†µê³¼")

    p_thr = 0.05
    num_cols_all = df.select_dtypes(include=[np.number]).columns.tolist()
    num_cols_all = [c for c in num_cols_all if c != target_col]

    if not st.session_state["done_1"]:
        if st.button("T-test ì‹¤í–‰ (p â‰¤ 0.05)"):
            g0 = df[df[target_col] == 0]
            g1 = df[df[target_col] == 1]

            rows = []
            passed = []

            for col in num_cols_all:
                x0 = g0[col].dropna()
                x1 = g1[col].dropna()
                if len(x0) < 2 or len(x1) < 2:
                    continue
                try:
                    _, p = stats.ttest_ind(x0, x1, equal_var=False, nan_policy="omit")
                except Exception:
                    continue

                rows.append((col, float(p)))
                if p <= p_thr:
                    passed.append(col)

            ttest_df = (
                pd.DataFrame(rows, columns=["feature", "p_value"])
                .sort_values("p_value")
                .reset_index(drop=True)
            )

            st.session_state["ttest_passed"] = passed
            st.session_state["ttest_table"] = ttest_df
            st.session_state["done_1"] = True
            st.rerun()

    # âœ… â‘  ê²°ê³¼ëŠ” í•­ìƒ í‘œì‹œ
    if st.session_state.get("done_1", False):
        passed = st.session_state.get("ttest_passed", [])
        st.success(f"âœ… â‘  ì™„ë£Œ: í†µê³¼ feature {len(passed)}ê°œ")
        st.markdown("### âœ… T-test í†µê³¼ feature ëª©ë¡")
        st.write(passed if len(passed) > 0 else "í†µê³¼ feature ì—†ìŒ")

        with st.expander("p-value ê²°ê³¼í‘œ ë³´ê¸°(ì„ íƒ)"):
            st.dataframe(
                st.session_state.get("ttest_table", pd.DataFrame()),
                use_container_width=True
            )

    st.divider()

    # =========================================================
    # â‘¡ ë°ì´í„° ì „ì²˜ë¦¬ (ë²„íŠ¼ë§Œ / IQR k=1.5 ê³ ì •)
    # =========================================================
    st.markdown("## â‘¡ ë°ì´í„° ì „ì²˜ë¦¬")
    st.caption("ì´ìƒì¹˜ ì œê±°(IQR,k=1.5) + ê²°ì¸¡ì¹˜ ì œê±° + ì›í•« ì¸ì½”ë”© (ìŠ¤ì¼€ì¼ë§ì€ â‘¢ì—ì„œ)")

    if not st.session_state.get("done_1", False):
        st.info("ğŸ”’ â‘  T-testë¥¼ ì™„ë£Œí•˜ë©´ â‘¡ê°€ í™œì„±í™”ë©ë‹ˆë‹¤.")
        st.stop()

    iqr_k = 1.5  # ê³ ì • (ì„¤ì • UI ì—†ìŒ)

    if not st.session_state.get("done_2", False):
        if st.button("ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰"):
            passed_num = st.session_state.get("ttest_passed", [])
        
            # âœ… í•µì‹¬: purposeëŠ” ë¬´ì¡°ê±´ ë²”ì£¼í˜•ìœ¼ë¡œ ì²˜ë¦¬ (ìˆ«ìì½”ë”© ë˜ì–´ ìˆì–´ë„ ì›í•«ë˜ê²Œ)
            if "purpose" in df.columns:
                df["purpose"] = df["purpose"].astype(str)
        
            # -------------------------------------------------
            # X êµ¬ì„±: ìˆ˜ì¹˜í˜•=passed_num + ë²”ì£¼í˜•=ì „ì²´(ë‹¨, target ì œì™¸)
            #  - ë²”ì£¼í˜•ì€ dtype ê¸°ë°˜ìœ¼ë¡œ ì¡ëŠ” ê²Œ ê°€ì¥ ì•ˆì •ì 
            # -------------------------------------------------
            numeric_all = df.select_dtypes(include=[np.number]).columns.tolist()
            cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()
            cat_cols = [c for c in cat_cols if c != target_col]
        
            # passed_numì´ ë¹„ì–´ë„ cat_colsë¡œ ì§„í–‰ ê°€ëŠ¥(ë‹¨, cat_colsë„ ë¹„ë©´ stop)
            use_cols = list(dict.fromkeys(passed_num + cat_cols))  # ì¤‘ë³µ ì œê±°+ìˆœì„œ ìœ ì§€
        
            if len(use_cols) == 0:
                st.error("ì „ì²˜ë¦¬ì— ì‚¬ìš©í•  featureê°€ ì—†ìŠµë‹ˆë‹¤.")
                st.stop()
        
            X = df[use_cols].copy()
            y = df[target_col].astype(int).copy()
        
            # (1) IQR ì´ìƒì¹˜ ì œê±°: passed ìˆ˜ì¹˜í˜•ì—ë§Œ ì ìš©
            if len(passed_num) > 0:
                tmp = pd.concat([X, y.rename(target_col)], axis=1)
                mask = pd.Series(True, index=tmp.index)
        
                for c in passed_num:
                    if c not in tmp.columns:
                        continue
                    s = tmp[c]
                    q1 = s.quantile(0.25)
                    q3 = s.quantile(0.75)
                    iqr = q3 - q1
                    if pd.isna(iqr) or iqr == 0:
                        continue
                    lo = q1 - iqr_k * iqr
                    hi = q3 + iqr_k * iqr
                    mask &= s.between(lo, hi) | s.isna()
        
                tmp = tmp.loc[mask].copy()
                y = tmp[target_col].astype(int)
                X = tmp.drop(columns=[target_col])
        
            # (2) ê²°ì¸¡ì¹˜ ì œê±°(ìš”ì²­: ì œê±°)
            tmp2 = pd.concat([X, y.rename(target_col)], axis=1).dropna()
            y = tmp2[target_col].astype(int)
            X = tmp2.drop(columns=[target_col])
        
            # (3) ì›í•« ì¸ì½”ë”©(1íšŒë§Œ)
            #     - ë²”ì£¼í˜•(purpose í¬í•¨) â†’ purpose_* ìƒì„±ë¨
            X_oh = pd.get_dummies(X, drop_first=True)
        
            # (4) í‘œì¤€í™” ëŒ€ìƒ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ê¸°ë¡ (â‘¢ì—ì„œ Train ê¸°ì¤€ ì ìš©)
            #     - ì›í•«ëœ ì»¬ëŸ¼(purpose_*)ì€ ìë™ìœ¼ë¡œ ì œì™¸ë¨(0/1)
            scale_cols = X.select_dtypes(include=[np.number]).columns.tolist()
        
            st.session_state["X_processed"] = X_oh
            st.session_state["y_processed"] = y
            st.session_state["scale_cols"] = scale_cols
            st.session_state["scaler"] = None
        
            # (ë””ë²„ê¹…ìš©: í•„ìš”í•˜ë©´ ì ê¹ ì¼°ë‹¤ê°€ ì§€ìš°ì„¸ìš”)
            # st.write("ì›í•« í›„ ì»¬ëŸ¼ ì˜ˆì‹œ:", [c for c in X_oh.columns if c.startswith("purpose_")][:10])
        
            st.session_state["done_2"] = True
            st.rerun()


    # âœ… â‘¡ ê²°ê³¼ í•­ìƒ í‘œì‹œ
    if st.session_state.get("done_2", False):
        Xp = st.session_state["X_processed"]
        yp = st.session_state["y_processed"]
        st.success("âœ… â‘¡ ì™„ë£Œ: ì „ì²˜ë¦¬ ê²°ê³¼ê°€ ì €ì¥ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
        st.write(f"ì „ì²˜ë¦¬ í›„ X shape: {Xp.shape} / y length: {len(yp)}")

    st.divider()

    # =========================================================
    # â‘¢ ë°ì´í„° ë¶„í• (8:2) + í‘œì¤€í™”(Train ê¸°ì¤€) â€” MLP ì „ìš©
    # =========================================================
    st.markdown("## â‘¢ ë°ì´í„° ë¶„í• (8:2) + í‘œì¤€í™”(Train ê¸°ì¤€)")
    st.caption("Train/Test ë¶„í•  í›„, Train ê¸°ì¤€ìœ¼ë¡œ í‘œì¤€í™”í•˜ì—¬ ë°ì´í„° ëˆ„ìˆ˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤. (MLP ì €ì¥)")
    
    if not st.session_state.get("done_2", False):
        st.info("ğŸ”’ â‘¡ ì „ì²˜ë¦¬ë¥¼ ì™„ë£Œí•˜ë©´ â‘¢ì´ í™œì„±í™”ë©ë‹ˆë‹¤.")
        st.stop()
    
    Xp = st.session_state["X_processed"]   # ì „ì²˜ë¦¬ í›„ ì „ì²´ ë³€ìˆ˜(ì›í•« í¬í•¨)
    yp = st.session_state["y_processed"]
    
    test_size = 0.2
    st.write(f"ë¶„í•  ë¹„ìœ¨: Train {int((1-test_size)*100)}% / Test {int(test_size*100)}% (ê³ ì •)")
    
    if not st.session_state.get("done_3", False):
        if st.button("ë°ì´í„° ë¶„í•  + í‘œì¤€í™”(Train ê¸°ì¤€) ì €ì¥"):
            # -----------------------------
            # A. ê³µí†µ ë¶„í•  (í•­ìƒ ì „ì²´ ë³€ìˆ˜ ì‚¬ìš©)
            # -----------------------------
            X_train, X_test, y_train, y_test = train_test_split(
                Xp, yp, test_size=test_size, random_state=42, stratify=yp
            )
    
            # -----------------------------
            # B. í‘œì¤€í™”(Train ê¸°ì¤€) â€” ìˆ˜ì¹˜í˜•ë§Œ
            # -----------------------------
            scaler = StandardScaler()
    
            scale_cols = st.session_state.get("scale_cols", [])
            scale_cols = [c for c in scale_cols if c in X_train.columns]
    
            X_train_mlp = X_train.copy()
            X_test_mlp  = X_test.copy()
    
            if len(scale_cols) > 0:
                X_train_mlp[scale_cols] = scaler.fit_transform(X_train[scale_cols])
                X_test_mlp[scale_cols]  = scaler.transform(X_test[scale_cols])
    
            # -----------------------------
            # C. ì €ì¥ (MLPë§Œ)
            # -----------------------------
            st.session_state["X_train_mlp"] = X_train_mlp
            st.session_state["X_test_mlp"]  = X_test_mlp
            st.session_state["y_train"] = y_train
            st.session_state["y_test"]  = y_test
    
            st.session_state["cols_mlp"] = list(X_train_mlp.columns)
            st.session_state["scaler"] = scaler
            st.session_state["scale_cols_applied"] = scale_cols
    
            st.session_state["done_3"] = True
            st.rerun()
    
    # âœ… â‘¢ ê²°ê³¼ í‘œì‹œ (MLPë§Œ)
    if st.session_state.get("done_3", False):
        required = ["X_train_mlp", "X_test_mlp", "cols_mlp"]
        missing = [k for k in required if k not in st.session_state or st.session_state.get(k) is None]
        if missing:
            st.warning("â‘¢ ê²°ê³¼ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤. ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”.")
            st.write("ëˆ„ë½ëœ í‚¤:", missing)
            st.session_state["done_3"] = False
            st.stop()
    
        st.success("âœ… â‘¢ ì™„ë£Œ: ë¶„í•  + í‘œì¤€í™”(Train ê¸°ì¤€) â€” MLP ì €ì¥ ì™„ë£Œ")
        st.write("MLP Train/Test:", st.session_state["X_train_mlp"].shape, "/", st.session_state["X_test_mlp"].shape)
    
        with st.expander("MLP ë³€ìˆ˜(í•­ìƒ ì „ì²´, purpose ì›í•« í¬í•¨) ë³´ê¸°"):
            st.write(st.session_state["cols_mlp"])

    




# ============================================================
# 3) ëª¨ë¸ë§(ì‹ ê²½ë§): MLP
# â‘¢ ë‹¨ê³„(ë°ì´í„° ë¶„í• ) ê²°ê³¼ë§Œ ì‚¬ìš©
# ============================================================
with tabs[2]:
    st.subheader("3) ëª¨ë¸ë§(ì‹ ê²½ë§): MLP í•™ìŠµ ë° ì˜ˆì¸¡í™•ë¥ (PD) ìƒì„±")

    # --------------------------------------------------------
    # ê°€ë“œ: â‘¢ ì™„ë£Œ ì—¬ë¶€
    # --------------------------------------------------------
    required = ["X_train_mlp", "X_test_mlp", "y_train", "y_test"]
    missing = [k for k in required if k not in st.session_state]
    
    if missing:
        st.info("ë¨¼ì € [â‘¡ ì „ì²˜ë¦¬ â†’ â‘¢ ë°ì´í„° ë¶„í• ]ë¥¼ ì™„ë£Œí•˜ì„¸ìš”. (MLPìš© ë°ì´í„°ê°€ ì•„ì§ ì €ì¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.)")
        st.stop()


    # --------------------------------------------------------
    # ì„¸ì…˜ì—ì„œ ë°ì´í„° ë¡œë“œ (í•µì‹¬)
    # --------------------------------------------------------
    X_train = st.session_state["X_train_mlp"]
    X_test  = st.session_state["X_test_mlp"]
    y_train = st.session_state["y_train"]
    y_test  = st.session_state["y_test"]

    # numpy ë³€í™˜ (MLP ì•ˆì •ì„±)
    Xtr = X_train.to_numpy()
    Xte = X_test.to_numpy()

    st.write("Train shape:", Xtr.shape, " / Test shape:", Xte.shape)

    # --------------------------------------------------------
    # í•˜ì´í¼íŒŒë¼ë¯¸í„°
    # --------------------------------------------------------
    c1, c2, c3, c4 = st.columns(4)
    with c1:
        h1 = st.number_input("Hidden Layer 1", 16, 512, 64, 16)
    with c2:
        h2 = st.number_input("Hidden Layer 2 (0ì´ë©´ 1ì¸µ)", 0, 512, 32, 16)
    with c3:
        alpha = st.number_input("L2 ê·œì œ(alpha)", 0.0, 0.01, 0.0001, 0.0001, format="%.4f")
    with c4:
        max_iter = st.number_input("max_iter", 200, 5000, 2000, 100)

    hidden = (int(h1),) if int(h2) == 0 else (int(h1), int(h2))

    early_stopping = st.checkbox("early_stopping ì‚¬ìš©", value=True)
    validation_fraction = st.slider("validation_fraction", 0.05, 0.30, 0.10, 0.01)

    # --------------------------------------------------------
    # í•™ìŠµ
    # --------------------------------------------------------
    if st.button("MLP í•™ìŠµ ì‹¤í–‰"):
        model = MLPClassifier(
            hidden_layer_sizes=hidden,
            activation="relu",
            solver="adam",
            alpha=float(alpha),
            max_iter=int(max_iter),
            random_state=42,
            early_stopping=early_stopping,
            validation_fraction=float(validation_fraction) if early_stopping else 0.1
        )

        model.fit(Xtr, y_train)

        st.session_state["model"] = model
        st.success("MLP í•™ìŠµ ì™„ë£Œ")

        # ì˜ˆì¸¡ í™•ë¥ 
        proba_test = model.predict_proba(Xte)[:, 1]
        st.session_state["proba_test"] = proba_test

        st.write("ì˜ˆì¸¡í™•ë¥ (PD) ìƒ˜í”Œ")
        st.write(pd.Series(proba_test).head(10))

        # loss curve
        if hasattr(model, "loss_curve_"):
            fig = plt.figure()
            ax = fig.add_subplot(111)
            ax.plot(model.loss_curve_)
            ax.set_xlabel("Iteration")
            ax.set_ylabel("Loss")
            ax.set_title("Training Loss Curve")
            st.pyplot(fig, clear_figure=True)

# ============================================================
# 4) ëª¨ë¸ í‰ê°€ & Segmentation (PD ë“±ê¸‰í‘œ)
# ============================================================
with tabs[3]:
    st.subheader("4) ëª¨ë¸ í‰ê°€ ë° PD Segmentation")

    # ------------------------------------------------------
    # Guard: ì˜ˆì¸¡í™•ë¥  ì¡´ì¬ ì—¬ë¶€
    # ------------------------------------------------------
    required = ["y_test", "proba_test"]
    missing = [k for k in required if k not in st.session_state or st.session_state.get(k) is None]
    if missing:
        st.warning("ë¨¼ì € MLP ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡í™•ë¥ (PD)ì„ ìƒì„±í•˜ì„¸ìš”.")
        st.write("ëˆ„ë½ëœ í‚¤:", missing)
        st.stop()

    import numpy as np
    import pandas as pd

    y_test = np.asarray(st.session_state["y_test"]).ravel()
    proba_test = np.asarray(st.session_state["proba_test"]).ravel()

    # ------------------------------------------------------
    # Type/shape safety
    # ------------------------------------------------------
    if len(y_test) != len(proba_test):
        st.error(
            f"y_test({len(y_test)})ì™€ proba_test({len(proba_test)}) ê¸¸ì´ê°€ ë‹¤ë¦…ë‹ˆë‹¤.\n"
            "â‘¢(ë¶„í• /í‘œì¤€í™”) ì´í›„ MLPë¥¼ ë‹¤ì‹œ í•™ìŠµí•˜ì„¸ìš”."
        )
        st.stop()

    # proba ë²”ìœ„ ì²´í¬
    if np.any(np.isnan(proba_test)) or np.any(np.isinf(proba_test)):
        st.error("proba_testì— NaN ë˜ëŠ” Infê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµí•˜ì„¸ìš”.")
        st.stop()

    # í™•ë¥  í´ë¦¬í•‘(ì•„ì£¼ ë“œë¬¸ ìˆ˜ì¹˜ë¬¸ì œ ë°©ì§€)
    proba_test = np.clip(proba_test, 1e-12, 1 - 1e-12)

    # ------------------------------------------------------
    # 4-A) ì„±ëŠ¥ í‰ê°€(ì§€í‘œ)
    # ------------------------------------------------------
    st.markdown("## âœ… 4-A) ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")

    from sklearn.metrics import (
        roc_auc_score, average_precision_score,
        accuracy_score, precision_score, recall_score, f1_score,
        confusion_matrix, classification_report,
        roc_curve, precision_recall_curve
    )

    # Threshold ì„¤ì •
    thr = st.slider("ë¶„ë¥˜ ì„ê³„ê°’(Threshold)", 0.05, 0.95, 0.50, 0.01)
    y_pred = (proba_test >= thr).astype(int)

    # ì£¼ìš” ì§€í‘œ
    auc = roc_auc_score(y_test, proba_test)
    pr_auc = average_precision_score(y_test, proba_test)

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)

    c1, c2, c3, c4, c5, c6 = st.columns(6)
    c1.metric("ROC-AUC", f"{auc:.4f}")
    c2.metric("PR-AUC(AP)", f"{pr_auc:.4f}")
    c3.metric("Accuracy", f"{acc:.4f}")
    c4.metric("Precision", f"{prec:.4f}")
    c5.metric("Recall", f"{rec:.4f}")
    c6.metric("F1", f"{f1:.4f}")

    # Confusion Matrix
    st.markdown("### Confusion Matrix")
    cm = confusion_matrix(y_test, y_pred)
    cm_df = pd.DataFrame(cm, index=["Actual 0", "Actual 1"], columns=["Pred 0", "Pred 1"])
    st.dataframe(cm_df, use_container_width=True)

    # Classification report
    with st.expander("Classification Report (ìƒì„¸)"):
        st.text(classification_report(y_test, y_pred, digits=4))

    # ROC Curve / PR Curve
    st.markdown("### ROC / PR Curve")
    fpr, tpr, _ = roc_curve(y_test, proba_test)
    pr_p, pr_r, _ = precision_recall_curve(y_test, proba_test)

    import matplotlib.pyplot as plt

    colA, colB = st.columns(2)
    with colA:
        fig1 = plt.figure()
        ax1 = fig1.add_subplot(111)
        ax1.plot(fpr, tpr)
        ax1.plot([0, 1], [0, 1], linestyle="--")
        ax1.set_xlabel("False Positive Rate")
        ax1.set_ylabel("True Positive Rate")
        ax1.set_title(f"ROC Curve (AUC={auc:.4f})")
        st.pyplot(fig1, clear_figure=True)

    with colB:
        fig2 = plt.figure()
        ax2 = fig2.add_subplot(111)
        ax2.plot(pr_r, pr_p)
        ax2.set_xlabel("Recall")
        ax2.set_ylabel("Precision")
        ax2.set_title(f"PR Curve (AP={pr_auc:.4f})")
        st.pyplot(fig2, clear_figure=True)

    # ------------------------------------------------------
    # (ì„ íƒ) KS ê³„ì‚°/í‘œì‹œ â€” ê¸ˆìœµ/ì‹ ìš©í‰ê°€ì—ì„œ ê°€ì‚°ì 
    # ------------------------------------------------------
    with st.expander("KS (ì„ íƒ)"):
        # KS = max(TPR - FPR)
        ks = float(np.max(tpr - fpr))
        st.write(f"KS Statistic: **{ks:.4f}**")

    st.divider()

    # ------------------------------------------------------
    # 4-B) PD Segmentation
    # ------------------------------------------------------
    st.markdown("## âœ… 4-B) PD Segmentation (Grade Table)")

    st.markdown("### ğŸ”¹ PD Segmentation ì„¤ì •")
    n_bins = st.slider("ë“±ê¸‰ ìˆ˜ (Grade ê°œìˆ˜)", 5, 20, 10, 1)

    # Segmentation ì‹¤í–‰ (ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©)
    try:
        agg, raw = segmentation_table(y_test=y_test, proba=proba_test, n_bins=int(n_bins))
    except TypeError:
        # ë„¤ í•¨ìˆ˜ê°€ positionalë§Œ ë°›ëŠ” ê²½ìš° ëŒ€ë¹„
        agg, raw = segmentation_table(y_test, proba_test, n_bins=int(n_bins))

    st.success("PD Segmentation Table ìƒì„± ì™„ë£Œ")

    # ê²°ê³¼ í‘œì‹œ
    st.markdown("### ğŸ“Š PD Segmentation Table")
    st.dataframe(agg, use_container_width=True)

    st.markdown("### ğŸ“„ ê°œë³„ ê´€ì¸¡ì¹˜ (ìƒ˜í”Œ)")
    st.dataframe(raw.head(20), use_container_width=True)

   
# ============================================================
# 5) ê³ ê° ì„¸ë¶„í™” ì „ëµ ì œì‹œ + ì‹œê°í™” (PD ê¸°ë°˜)
#   - ì…ë ¥: y_test, proba_test (Tab3/4ì—ì„œ ìƒì„±ëœ ê²ƒ)
#   - ì¶œë ¥: Grade Table + Segment Table + ì „ëµ + ì‹œê°í™” 3ì¢…
# ============================================================
with tabs[4]:
    st.subheader("5) ê³ ê° ì„¸ë¶„í™” ì „ëµ ì œì‹œ + ì‹œê°í™” (PD ê¸°ë°˜)")

    # --------------------------------------------------------
    # Guard
    # --------------------------------------------------------
    required = ["y_test", "proba_test"]
    missing = [k for k in required if k not in st.session_state or st.session_state.get(k) is None]
    if missing:
        st.warning("ë¨¼ì € MLP ëª¨ë¸ì„ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡í™•ë¥ (PD)ì„ ìƒì„±í•˜ì„¸ìš”.")
        st.write("ëˆ„ë½ëœ í‚¤:", missing)
        st.stop()

    import numpy as np
    import pandas as pd
    import matplotlib.pyplot as plt

    y_test = np.asarray(st.session_state["y_test"]).ravel().astype(int)
    proba_test = np.asarray(st.session_state["proba_test"]).ravel().astype(float)

    if len(y_test) != len(proba_test):
        st.error(f"y_test({len(y_test)})ì™€ proba_test({len(proba_test)}) ê¸¸ì´ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")
        st.stop()

    if np.any(np.isnan(proba_test)) or np.any(np.isinf(proba_test)):
        st.error("proba_testì— NaN/Infê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµí•˜ì„¸ìš”.")
        st.stop()

    proba_test = np.clip(proba_test, 1e-12, 1 - 1e-12)

    # --------------------------------------------------------
    # A) Grade ì„¤ì • + Risk Segment êµ¬ì¡°(ê³ ì • + ê°œë…ë„ í‘œì‹œ)
    # --------------------------------------------------------
    st.markdown("### 5-A) PD ê¸°ë°˜ ê³ ê° ë“±ê¸‰í™”(Grade) + Risk Segment ì„¤ì •")

    n_bins = 14

    method = "ë¶„ìœ„ìˆ˜(qcut) ê¸°ë°˜"
    
    # âœ… Risk Segment ë¹„ì¤‘ ê³ ì • (30/40/30)
    low_pct = 0.30
    mid_pct = 0.40
    high_pct = 0.30

    st.markdown(
        """
#### ğŸ“Œ Risk Segment êµ¬ì¡°(ê³ ì •, 30/40/30)
"""
    )

    df_seg = pd.DataFrame({"y": y_test, "pd": proba_test})

    # Grade ìƒì„± (ë‚®ì€ PD â†’ ë‚®ì€ Grade)
    try:
        if method.startswith("ë¶„ìœ„ìˆ˜"):
            df_seg["grade"] = pd.qcut(df_seg["pd"], q=int(n_bins), labels=False, duplicates="drop")
        else:
            df_seg["grade"] = pd.cut(df_seg["pd"], bins=int(n_bins), labels=False, include_lowest=True)
        df_seg["grade"] = df_seg["grade"].astype(int) + 1
    except Exception as e:
        st.error(f"Grade ìƒì„± ì‹¤íŒ¨: {e}")
        st.stop()

    # --------------------------------------------------------
    # B) Grade Summary (ë³´ê³ ì„œìš© í•µì‹¬ í‘œ)
    # --------------------------------------------------------
    st.markdown("### 5-B) Grade ìš”ì•½ í…Œì´ë¸”")

    grade_summary = (
        df_seg.groupby("grade")
        .agg(
            n=("y", "size"),
            bad=("y", "sum"),
            bad_rate=("y", "mean"),
            avg_pd=("pd", "mean"),
            min_pd=("pd", "min"),
            max_pd=("pd", "max"),
        )
        .reset_index()
        .sort_values("grade")
    )
    grade_summary["share"] = grade_summary["n"] / grade_summary["n"].sum()
    grade_summary["cum_share"] = grade_summary["share"].cumsum()
    grade_summary["cum_bad"] = grade_summary["bad"].cumsum()
    grade_summary["cum_bad_rate"] = grade_summary["cum_bad"] / grade_summary["n"].cumsum()

    st.dataframe(grade_summary, use_container_width=True)

    # --------------------------------------------------------
    # C) Risk Segment (Low/Medium/High) - âœ… ìŠ¬ë¼ì´ë” ì œê±°, ê³ ì • ë¹„ì¤‘ ì‚¬ìš©
    # --------------------------------------------------------
    st.markdown("### 5-C) Risk Segment (Low / Medium / High) ê²°ê³¼")

    # ê³ ê° ëˆ„ì  ê¸°ì¤€ ì»· ê³„ì‚° (low_pct/high_pct ê³ ì •ê°’ ì‚¬ìš©)
    tmp = grade_summary.copy()
    tmp["cum_n"] = tmp["n"].cumsum()
    total_n = tmp["n"].sum()

    low_cut_n = total_n * low_pct
    high_cut_n = total_n * (1 - high_pct)

    low_cut_grade = int(tmp.loc[tmp["cum_n"] >= low_cut_n, "grade"].iloc[0])
    high_cut_grade = int(tmp.loc[tmp["cum_n"] >= high_cut_n, "grade"].iloc[0])

    def assign_segment(g):
        if g <= low_cut_grade:
            return "Low Risk"
        elif g >= high_cut_grade:
            return "High Risk"
        else:
            return "Medium Risk"

    df_seg["segment"] = df_seg["grade"].apply(assign_segment)

    segment_summary = (
        df_seg.groupby("segment")
        .agg(
            n=("y", "size"),
            bad=("y", "sum"),
            bad_rate=("y", "mean"),
            avg_pd=("pd", "mean"),
        )
        .reset_index()
    )

    # ìˆœì„œ ì •ë ¬
    order = pd.Categorical(
        segment_summary["segment"],
        categories=["Low Risk", "Medium Risk", "High Risk"],
        ordered=True
    )
    segment_summary = segment_summary.assign(_ord=order).sort_values("_ord").drop(columns=["_ord"])
    segment_summary["share"] = segment_summary["n"] / segment_summary["n"].sum()

    # ì»· ì •ë³´ë„ ê°™ì´ ë³´ì—¬ì£¼ê¸°(ì„¤ëª…ìš©)
    st.info(f"ì„¸ê·¸ë¨¼íŠ¸ ì»·(Grade ê¸°ì¤€): Low â‰¤ G{low_cut_grade} / High â‰¥ G{high_cut_grade} (ë¹„ì¤‘ 30/40/30 ê³ ì •)")
    st.dataframe(segment_summary, use_container_width=True)

    # --------------------------------------------------------
    # D) ì „ëµ ì œì‹œ (í‘œ)
    # --------------------------------------------------------
    st.markdown("### 5-D) ê³ ê° ì„¸ë¶„í™” ì „ëµ(ì˜ˆì‹œ)")

    strategy_df = pd.DataFrame([
        {
            "Segment": "Low Risk",
            "ì •ì˜": "PD ë‚®ìŒ / ë¶€ì‹¤ë¥  ë‚®ìŒ",
            "ê¶Œì¥ ì „ëµ": "ìš°ëŒ€ê¸ˆë¦¬, í•œë„ ìƒí–¥, ìë™ìŠ¹ì¸ ë¹„ì¤‘ í™•ëŒ€",
            "ëª©í‘œ": "ìˆ˜ìµ ê·¹ëŒ€í™”(ìš°ëŸ‰ ê³ ê° ìœ ì§€/í™•ëŒ€)"
        },
        {
            "Segment": "Medium Risk",
            "ì •ì˜": "PD ì¤‘ê°„ / ê´€ë¦¬ í•„ìš”",
            "ê¶Œì¥ ì „ëµ": "ì¡°ê±´ë¶€ ìŠ¹ì¸, ì¶”ê°€ ì‹¬ì‚¬, ëª¨ë‹ˆí„°ë§ ê°•í™”",
            "ëª©í‘œ": "ë¦¬ìŠ¤í¬ ê´€ë¦¬ + ì„ ë³„ì  ìˆ˜ìµ"
        },
        {
            "Segment": "High Risk",
            "ì •ì˜": "PD ë†’ìŒ / ë¶€ì‹¤ë¥  ë†’ìŒ",
            "ê¶Œì¥ ì „ëµ": "ëŒ€ì¶œ ì œí•œ/ê±°ì ˆ, ë‹´ë³´Â·ë³´ì¦ ìš”êµ¬, ê¸ˆë¦¬ ìƒí–¥, ì‚¬í›„ê´€ë¦¬ ê°•í™”",
            "ëª©í‘œ": "ì†ì‹¤ ìµœì†Œí™”(ë¦¬ìŠ¤í¬ íšŒí”¼)"
        },
    ])
    st.dataframe(strategy_df, use_container_width=True)

    # --------------------------------------------------------
    # E) ì‹œê°í™”
    # --------------------------------------------------------
    st.markdown("### 5-E) ì‹œê°í™”")

    colA, colB = st.columns(2)

    # 1) Gradeë³„ ê³ ê° ìˆ˜ ë¶„í¬
    with colA:
        fig = plt.figure()
        ax = fig.add_subplot(111)
        ax.bar(grade_summary["grade"], grade_summary["n"])
        ax.set_xlabel("Grade (ë‚®ì€ PD â†’ ë†’ì€ PD)")
        ax.set_ylabel("ê³ ê° ìˆ˜")
        ax.set_title("Customer Count by Grade")
        st.pyplot(fig, clear_figure=True)

    # 2) Gradeë³„ ì‹¤ì œ ë¶€ì‹¤ë¥  vs í‰ê·  PD
    with colB:
        fig = plt.figure()
        ax = fig.add_subplot(111)
        ax.plot(grade_summary["grade"], grade_summary["bad_rate"], marker="o", label="Observed Bad Rate")
        ax.plot(grade_summary["grade"], grade_summary["avg_pd"], marker="o", label="Average PD")
        ax.set_xlabel("Grade")
        ax.set_ylabel("Rate")
        ax.set_title("Bad Rate vs Avg PD by Grade")
        ax.legend()
        st.pyplot(fig, clear_figure=True)

    # 3) ëˆ„ì  ê³ ê°ë¹„ì¤‘ vs ëˆ„ì  ë¶€ì‹¤ë¹„ì¤‘ (High PDë¶€í„°)
    st.markdown("#### ëˆ„ì  ë¶€ì‹¤ í¬ì°© (Lift-like)")

    gs_desc = grade_summary.sort_values("grade", ascending=False).copy()
    gs_desc["share"] = gs_desc["n"] / gs_desc["n"].sum()
    gs_desc["bad_share"] = gs_desc["bad"] / max(gs_desc["bad"].sum(), 1)

    gs_desc["cum_share"] = gs_desc["share"].cumsum()
    gs_desc["cum_bad_share"] = gs_desc["bad_share"].cumsum()

    fig = plt.figure()
    ax = fig.add_subplot(111)
    ax.plot(gs_desc["cum_share"], gs_desc["cum_bad_share"], marker="o")
    ax.plot([0, 1], [0, 1], linestyle="--")
    ax.set_xlabel("Cumulative Customer Share (High PD â†’ Low PD)")
    ax.set_ylabel("Cumulative Bad Share")
    ax.set_title("Cumulative Bad Capture Curve")
    st.pyplot(fig, clear_figure=True)

    # --------------------------------------------------------
    # F) ë‹¤ìš´ë¡œë“œ
    # --------------------------------------------------------
    with st.expander("CSV ë‹¤ìš´ë¡œë“œ"):
        st.download_button(
            "Grade Summary CSV ë‹¤ìš´ë¡œë“œ",
            data=grade_summary.to_csv(index=False).encode("utf-8-sig"),
            file_name="pd_grade_summary.csv",
            mime="text/csv"
        )
        st.download_button(
            "Segment Summary CSV ë‹¤ìš´ë¡œë“œ",
            data=segment_summary.to_csv(index=False).encode("utf-8-sig"),
            file_name="pd_segment_summary.csv",
            mime="text/csv"
        )
